{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470e409a",
   "metadata": {},
   "source": [
    "# 1- Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation and preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "# Load training features and labels from CSV files\n",
    "x_train = pd.read_csv(\"feature.csv\")\n",
    "y_train = pd.read_csv(\"class_labels.csv\")\n",
    "\n",
    "# Convert the labels to a 1-dimensional numpy array for compatibility with scikit-learn\n",
    "y_train = y_train.iloc[:, 0].values.ravel()\n",
    "\n",
    "# Feature Selection\n",
    "selector = VarianceThreshold()\n",
    "x_train = selector.fit_transform(x_train)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "# Feature Normalization\n",
    "x_train = preprocessing.normalize(x_train, norm='l2')\n",
    "\n",
    "# Print the shapes of the processed labels and features\n",
    "print(y_train.shape)  \n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3cad4c",
   "metadata": {},
   "source": [
    "# 2- Random Forest algorithm + GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, make_scorer, precision_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a pipeline with three steps: scaling, feature selection, and classification\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # First, scale features to normalize them\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif)),  # Then select the best features based on ANOVA F-test\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=1))  # Finally, use a RandomForestClassifier\n",
    "])\n",
    "\n",
    "# Define a grid of parameters for the grid search\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],  # Number of trees in the random forest\n",
    "    'classifier__max_depth': [5, 10, 20],  # Maximum depth of the trees\n",
    "}\n",
    "\n",
    "\n",
    "# Configure a KFold cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Set up GridSearchCV to find the best parameters within the defined grid\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=cv, verbose=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the grid search object to find the best model\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "best_clf = grid_search.best_estimator_  # Extract the best estimator\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the best model using cross-validation for different metrics\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\n************** Accuracy **************\\n\")\n",
    "scoring_metric = 'accuracy'\n",
    "cv_scores = cross_val_score(best_clf, x_train, y_train, cv=cv, scoring=scoring_metric)\n",
    "print(f\"CV Scores ({scoring_metric}): {cv_scores}\")\n",
    "print(f\"Mean CV Score ({scoring_metric}): {np.mean(cv_scores)}\")\n",
    "print(f\"Standard Deviation of CV Score ({scoring_metric}): {np.std(cv_scores)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Recall\n",
    "print(\"\\n\\n************** Recall **************\\n\")\n",
    "recall_scorer = make_scorer(recall_score, average='macro')\n",
    "cv_scores = cross_val_score(best_clf, x_train, y_train, cv=cv, scoring=recall_scorer)\n",
    "print(f\"CV Scores (recall): {cv_scores}\")\n",
    "print(f\"Mean CV Score (recall): {np.mean(cv_scores)}\")\n",
    "print(f\"Standard Deviation of CV Score (recall): {np.std(cv_scores)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Precision (Corrected to use precision_scorer)\n",
    "print(\"\\n\\n************** Precision Score **************\\n\")\n",
    "precision_scorer = make_scorer(precision_score, average='macro')\n",
    "cv_scores = cross_val_score(best_clf, x_train, y_train, cv=cv, scoring=precision_scorer)  # Corrected to use precision_scorer\n",
    "print(f\"CV Scores (precision_score): {cv_scores}\")\n",
    "print(f\"Mean CV Score (precision_score): {np.mean(cv_scores)}\")\n",
    "print(f\"Standard Deviation of CV Score (precision_score): {np.std(cv_scores)}\")\n",
    "\n",
    "\n",
    "\n",
    "# F1 Score (Corrected to use f1_scorer)\n",
    "print(\"\\n\\n************** F1 Score **************\\n\")\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "cv_scores = cross_val_score(best_clf, x_train, y_train, cv=cv, scoring=f1_scorer)  # Corrected to use f1_scorer\n",
    "print(f\"CV Scores (f1_score): {cv_scores}\")\n",
    "print(f\"Mean CV Score (f1_score): {np.mean(cv_scores)}\")\n",
    "print(f\"Standard Deviation of CV Score (f1_score): {np.std(cv_scores)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "print(\"\\n\\n************** Confusion Matrix **************\\n\")\n",
    "y_pred = cross_val_predict(best_clf, x_train, y_train, cv=cv)  # Generate predictions using cross-validation\n",
    "cm = confusion_matrix(y_train, y_pred)  # Compute the confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', cbar=False)  # Plot the confusion matrix\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c3ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
